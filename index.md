---
title: " Home"
layout: default
---

Suppose you are a software engineer involved in AI software.
Suppose further you believe that you
have ethical duties  to society as a whole, and not just the current organization where you work.
What could you do about that?

The advice we offer is to say that
it is possible for engineers to educate their organizations on the benefit of
ethics using a "stick and carrot" approach:

- The "carrot" would be to observe that
the tools we call “ethical” also come with other attractive
services. For example, in this book we show that services like  explanation and monitoring and repair are part-and-parcel
of ethically-aligned-design.
That is, 
engineers can sell their organization on being ethical as a side-effect
of making their systems more comprehensible and more reliable and
more adaptable.

- The "stick" in this case is to say that it makes good business sense not to get sued.
This is an important point since an increasingly litigious
general public now  frets
that
AI
tools are not always benign or beneficial. 


This book is in two parts:

* There is the pragmatic part where we step through nine parts of standard industrial AI
practice. At each step, we offer examples on best/worst practices as well as notes on how,
pragmatically speaking, that step can be augmented with more ethics.

*  There is the also the idealized ethical part. KARROT is a reference implementation of an ethically-aligned design for data mining and optimization.
KARROT is not a replacement for current industrial tools. Rather, it is a tutorial device for demonstrating ethically-aligned design.
Its purpose of KARROT is to 
 (a) introduce a set of ethically-aligned-design concepts;
(b) show how to they might be opearationalized;
(c) offer an open source library where some parts of ethically-aligned design can be added to an existing design (if the opportunity
to do so arises);
(d)  understand the computational bottlenecks of ethically aligned design;
(e) propose research directions that could lead to better ethically align design, in the future.


Before beginning, we stress the following points. Our code is just **one way**, and not the **only way**,   to operationalize ethics. Ideally, the reader disagrees with our design choices and proposes better ones— which would be a good thing since it would mean that more people are spending more time reflecting and building systems that are more ethically-aligned.
